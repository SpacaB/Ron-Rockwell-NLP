{
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "signature": "sha256:f7e81d5dedf994e3629ac7133b29664cbfe4298122f6271e50374e4328969bf2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before we do anything, we'll import some libraries that we'll need for the exercise."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.tokenize import RegexpTokenizer\n",
      "from nltk.corpus import stopwords\n",
      "from nltk import FreqDist\n",
      "from __future__ import division"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I originally wrote my short story in Microsoft Word. To convert it to a text file, I just copied & pasted the story from Word into a .txt in Notepad++. Now we have an easy-to-work-with format: the entirety of Ron Rockwell in just a text file. Let's open it with Python. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "storytext = open(\"ronrockwell.txt\").read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we'll write a function that further preprocesses the text. The output is an object that consists of all the words found in Ron Rockwell as word \"tokens\". "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def preprocess(sentence):\n",
      "\tsentence = sentence.lower()\n",
      "\ttokenizer = RegexpTokenizer(r'\\w+')\n",
      "\ttokens = tokenizer.tokenize(sentence)\n",
      "\treturn \" \".join(tokens)\n",
      "\n",
      "preprocessedStory = preprocess(storytext)\n",
      "\n",
      "tokens = nltk.word_tokenize(preprocessedStory)\n",
      "print tokens[0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['\\xef', 'that', 's', 'it', 'for', 'today', 'remember', 'homework', 'is', 'due']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can look at what the tokens are in the output.\n",
      "\n",
      "Let's define a short function to identify an introductory metric for our story. The Lexical Diversity represents the ratio of unique words used to the total number of words in the story. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def lexical_diversity(text):\n",
      "    return len(set(text)) / len(text)\n",
      "\n",
      "lexical_diversity(tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "0.3222842139809649"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's check our math. How many tokens are there, total?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "len(tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "3047"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How many unique tokens are there in that set?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "len(set(tokens))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "982"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "982/3047 is equal to a .32 Lexical Diversity score.\n",
      "\n",
      "The FreqDist() function turns our set of tokens into a Frequency Distribution object, giving us the frequencies of all tokens in my story."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "fdist1 = FreqDist(tokens)\n",
      "print(fdist1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<FreqDist: 'the': 108, 'and': 105, 'to': 98, 'a': 82, 'of': 69, 'ron': 61, 'in': 56, 'i': 47, 'was': 47, 'his': 45, ...>\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's have a quick look at our first ten items"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "fdist1.items()[0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[('the', 108),\n",
        " ('and', 105),\n",
        " ('to', 98),\n",
        " ('a', 82),\n",
        " ('of', 69),\n",
        " ('ron', 61),\n",
        " ('in', 56),\n",
        " ('i', 47),\n",
        " ('was', 47),\n",
        " ('his', 45)]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not many of those words are useful for analysis. \"The\", \"and\", \"to\", \"a\", and \"of\" are all used in the English language to provide basic sentence structure. We want to eliminate these kinds of words and only focus on the words that have significance in giving us information about the story. These words are called \"stopwords\", and we are going to eliminate them by importing a pre-made list of stopwords and eliminating them from our list of word tokens."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from nltk.corpus import stopwords\n",
      "stop = stopwords.words('english')\n",
      "remstop = [i for i in tokens if i not in stop]\n",
      "remstop[0:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "['\\xef',\n",
        " 'today',\n",
        " 'remember',\n",
        " 'homework',\n",
        " 'due',\n",
        " 'next',\n",
        " 'class',\n",
        " 'forget',\n",
        " 'test',\n",
        " 'friday',\n",
        " 'everything',\n",
        " 've',\n",
        " 'learned',\n",
        " 'chain',\n",
        " 'rule',\n",
        " 'll',\n",
        " 'office',\n",
        " 'wednesday',\n",
        " 'twelve',\n",
        " 'two']"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How many total words are left?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(remstop)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "1542"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How many unique words made it?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(set(remstop))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "876"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's turn our stopword-free list of tokens into a Frequency Distribution object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fdist2 = FreqDist(remstop)\n",
      "print(fdist2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<FreqDist: 'ron': 61, 'molly': 25, 'calculus': 16, 'students': 15, 'class': 13, 'time': 13, 'mathematics': 10, 'really': 10, 'wasn': 10, 'know': 9, ...>\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Now we're getting somewhere. Let's see a list of the top 20 most common non-stopwords in my short story, Ron Rockwell."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fdist2.items()[0:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "[('ron', 61),\n",
        " ('molly', 25),\n",
        " ('calculus', 16),\n",
        " ('students', 15),\n",
        " ('class', 13),\n",
        " ('time', 13),\n",
        " ('mathematics', 10),\n",
        " ('really', 10),\n",
        " ('wasn', 10),\n",
        " ('know', 9),\n",
        " ('life', 9),\n",
        " ('office', 9),\n",
        " ('professor', 9),\n",
        " ('took', 9),\n",
        " ('college', 8),\n",
        " ('wanted', 8),\n",
        " ('felt', 7),\n",
        " ('get', 7),\n",
        " ('like', 7),\n",
        " ('things', 7)]"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This makes a lot more sense. The top two most common words are the names of the two main characters, Ron and Molly. The third most common word, \"calculus\", is how they are connected: Ron is the professor for Molly's calculus class. The next four most common words, \"students\", \"class\", \"time\", and \"mathematics\" seem to make sense in this context.\n",
      "\n",
      "Ok, that's pretty neat. Now let's take a measure of how rich our vocabulary was with the stopwords removed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lexical_diversity(remstop)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "0.5680933852140078"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's higher than the .32 score we saw earlier. Removing all those common stopwords makes obviously makes our use of language seem more diverse.\n",
      "\n",
      "Ok, so in order to save some of this data for later--in this case, the top 20 most common non-stopwords, we'll turn that into a list, which we'll then write out as a .csv file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "array = fdist2.items()[0:20]\n",
      "mylist = [list(i) for i in array]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, we can take this data and export it as a .csv file for further analysis in R or Excel."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "with open('newfile.csv', 'wb') as result:\n",
      "    writer = csv.writer(result, dialect='excel')\n",
      "    writer.writerows(array)\n",
      "\n",
      "with open('tokens.csv', 'wb') as result:\n",
      "    writer = csv.writer(result, dialect='excel')\n",
      "    writer.writerow(remstop)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can download the files here as proof that this worked: "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}